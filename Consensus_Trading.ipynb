{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "746ea643",
   "metadata": {},
   "source": [
    "## Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "28b63474",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "def load_and_clean_data(file_path):\n",
    "    \"\"\"Load and perform initial cleaning of insider trading data\"\"\"\n",
    "    df = pd.read_csv(file_path)\n",
    "    \n",
    "    # Clean column names\n",
    "    df.columns = df.columns.str.strip().str.replace('\\n', '')\n",
    "    \n",
    "    # Convert date columns to datetime\n",
    "    date_cols = ['DATE OF ALLOTMENT/ACQUISITION FROM', 'DATE OF ALLOTMENT/ACQUISITION TO']\n",
    "    for col in date_cols:\n",
    "        df[col] = pd.to_datetime(df[col], format='%d-%b-%Y', errors='coerce')\n",
    "    \n",
    "    # Clean numeric columns\n",
    "    df['NO. OF SECURITIES (ACQUIRED/DISPLOSED)'] = pd.to_numeric(df['NO. OF SECURITIES (ACQUIRED/DISPLOSED)'], errors='coerce')\n",
    "    \n",
    "    # Clean VALUE column\n",
    "    df['VALUE OF SECURITY (ACQUIRED/DISPLOSED)'] = df['VALUE OF SECURITY (ACQUIRED/DISPLOSED)'].replace('-', np.nan)\n",
    "    df['VALUE OF SECURITY (ACQUIRED/DISPLOSED)'] = pd.to_numeric(df['VALUE OF SECURITY (ACQUIRED/DISPLOSED)'], errors='coerce')\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "84d95e8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load_and_clean_data(\"CF-Insider-Trading-equities-14-07-2022-to-14-07-2025.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "8a6c5433",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"Cleaned_Data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6bf892c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['SYMBOL', 'COMPANY', 'REGULATION', 'NAME OF THE ACQUIRER/DISPOSER',\n",
       "       'CATEGORY OF PERSON', 'TYPE OF SECURITY (PRIOR)',\n",
       "       'NO. OF SECURITY (PRIOR)', '% SHAREHOLDING (PRIOR)',\n",
       "       'TYPE OF SECURITY (ACQUIRED/DISPLOSED)',\n",
       "       'NO. OF SECURITIES (ACQUIRED/DISPLOSED)',\n",
       "       'VALUE OF SECURITY (ACQUIRED/DISPLOSED)',\n",
       "       'ACQUISITION/DISPOSAL TRANSACTION TYPE', 'TYPE OF SECURITY (POST)',\n",
       "       'NO. OF SECURITY (POST)', '% POST',\n",
       "       'DATE OF ALLOTMENT/ACQUISITION FROM',\n",
       "       'DATE OF ALLOTMENT/ACQUISITION TO', 'DATE OF INITMATION TO COMPANY',\n",
       "       'MODE OF ACQUISITION', 'DERIVATIVE TYPE SECURITY',\n",
       "       'DERIVATIVE CONTRACT SPECIFICATION', 'NOTIONAL VALUE(BUY)',\n",
       "       'NUMBER OF UNITS/CONTRACT LOT SIZE (BUY)', 'NOTIONAL VALUE(SELL)',\n",
       "       'NUMBER OF UNITS/CONTRACT LOT SIZE  (SELL)', 'EXCHANGE', 'REMARK',\n",
       "       'BROADCASTE DATE AND TIME', 'XBRL'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c63b1006",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2dbcb72a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_relevant_data(df):\n",
    "    \"\"\"Filter for relevant insider trading data\"\"\"\n",
    "    # Filter out rows with missing critical information\n",
    "    df_filtered = df.dropna(subset=[\n",
    "        'SYMBOL', 'DATE OF ALLOTMENT/ACQUISITION FROM', \n",
    "        'NO. OF SECURITIES (ACQUIRED/DISPLOSED)',\n",
    "        'ACQUISITION/DISPOSAL TRANSACTION TYPE'\n",
    "    ])\n",
    "    \n",
    "    # Filter for only Buy and Sell transactions\n",
    "    df_filtered = df_filtered[df_filtered['ACQUISITION/DISPOSAL TRANSACTION TYPE'].isin(['Buy', 'Sell'])]\n",
    "    \n",
    "    # Filter for market transactions only\n",
    "    market_modes = ['Market Sale', 'Market Purchase', 'Off Market']\n",
    "    df_filtered = df_filtered[df_filtered['MODE OF ACQUISITION'].isin(market_modes)]\n",
    "    \n",
    "    # Filter for significant insider categories\n",
    "    significant_categories = ['Promoters', 'Promoter Group', 'Director', 'Key Managerial Personnel', 'Employees']\n",
    "    df_filtered = df_filtered[df_filtered['CATEGORY OF PERSON'].isin(significant_categories)]\n",
    "    \n",
    "    # Create transaction_type column (1 for Buy, -1 for Sell)\n",
    "    df_filtered['transaction_type'] = df_filtered['ACQUISITION/DISPOSAL TRANSACTION TYPE'].map({\n",
    "        'Buy': 1, 'Sell': -1\n",
    "    })\n",
    "    \n",
    "    # Filter for reasonable date range (2022-2025)\n",
    "    start_date = pd.to_datetime('2022-01-01')\n",
    "    end_date = pd.to_datetime('2025-12-31')\n",
    "    df_filtered = df_filtered[\n",
    "        (df_filtered['DATE OF ALLOTMENT/ACQUISITION FROM'] >= start_date) & \n",
    "        (df_filtered['DATE OF ALLOTMENT/ACQUISITION FROM'] <= end_date)\n",
    "    ]\n",
    "    \n",
    "    return df_filtered"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00b3d6ab",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "24c9f80f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_insider_weights():\n",
    "    \"\"\"Create weights for different insider categories\"\"\"\n",
    "    return {\n",
    "        'Promoters': 4,\n",
    "        'Promoter Group': 3,\n",
    "        'Director': 2,\n",
    "        'Key Managerial Personnel': 1\n",
    "    }\n",
    "\n",
    "def add_insider_weights(df):\n",
    "    \"\"\"Add insider weights to dataframe\"\"\"\n",
    "    weights = create_insider_weights()\n",
    "    df['insider_weight'] = df['CATEGORY OF PERSON'].map(weights)\n",
    "    return df\n",
    "\n",
    "def calculate_transaction_metrics(df):\n",
    "    \"\"\"Calculate additional metrics for each transaction\"\"\"\n",
    "    # Calculate transaction value (if available)\n",
    "    df['transaction_value'] = df['VALUE OF SECURITY (ACQUIRED/DISPLOSED)'].fillna(0)\n",
    "    \n",
    "    # Calculate weighted transaction score\n",
    "    df['weighted_score'] = df['transaction_type'] * df['insider_weight'] * np.log1p(df['NO. OF SECURITIES (ACQUIRED/DISPLOSED)'])\n",
    "    \n",
    "    # Add transaction date as reference\n",
    "    df['transaction_date'] = df['DATE OF ALLOTMENT/ACQUISITION FROM']\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a29d499b",
   "metadata": {},
   "source": [
    "## Consensus Signal Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0016920a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConsensusParameters:\n",
    "    def __init__(self, lookback_window=3, min_insiders=1, min_net_score=0.02, \n",
    "        signal_hold_period=1, min_transaction_value=0):\n",
    "        self.lookback_window = lookback_window  # days\n",
    "        self.min_insiders = min_insiders        # minimum number of insiders needed\n",
    "        self.min_net_score = min_net_score      # minimum weighted net score\n",
    "        self.signal_hold_period = signal_hold_period  # days to hold signal\n",
    "        self.min_transaction_value = min_transaction_value  # minimum transaction value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "806f6357",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_consensus_signals(df, params):\n",
    "    \"\"\"Generate consensus insider trading signals\"\"\"\n",
    "    signals = []\n",
    "    \n",
    "    # Group by company symbol\n",
    "    for symbol in df['SYMBOL'].unique():\n",
    "        company_data = df[df['SYMBOL'] == symbol].copy()\n",
    "        company_data = company_data.sort_values('transaction_date')\n",
    "        \n",
    "        # Create rolling window analysis\n",
    "        signals.extend(analyze_company_consensus(company_data, params))\n",
    "    \n",
    "    return pd.DataFrame(signals)\n",
    "\n",
    "def analyze_company_consensus(company_data, params):\n",
    "    \"\"\"Analyze consensus for a single company\"\"\"\n",
    "    signals = []\n",
    "    \n",
    "    # Get unique transaction dates\n",
    "    transaction_dates = company_data['transaction_date'].unique()\n",
    "    \n",
    "    for date in transaction_dates:\n",
    "        # Define lookback window\n",
    "        window_start = date - timedelta(days=params.lookback_window)\n",
    "        window_end = date\n",
    "        \n",
    "        # Filter data within window\n",
    "        window_data = company_data[\n",
    "            (company_data['transaction_date'] >= window_start) & \n",
    "            (company_data['transaction_date'] <= window_end)\n",
    "        ]\n",
    "        \n",
    "        # Calculate consensus metrics\n",
    "        signal = calculate_consensus_signal(window_data, date, params)\n",
    "        if signal:\n",
    "            signals.append(signal)\n",
    "    \n",
    "    return signals\n",
    "\n",
    "def calculate_consensus_signal(window_data, signal_date, params):\n",
    "    \"\"\"Calculate consensus signal for a time window\"\"\"\n",
    "    if len(window_data) < params.min_insiders:\n",
    "        return None\n",
    "    \n",
    "    # Count unique insiders\n",
    "    unique_insiders = window_data['NAME OF THE ACQUIRER/DISPOSER'].nunique()\n",
    "    if unique_insiders < params.min_insiders:\n",
    "        return None\n",
    "    \n",
    "    # Calculate net weighted score\n",
    "    net_score = window_data['weighted_score'].sum()\n",
    "    \n",
    "    # Calculate transaction direction consensus\n",
    "    buy_score = window_data[window_data['transaction_type'] == 1]['weighted_score'].sum()\n",
    "    sell_score = abs(window_data[window_data['transaction_type'] == -1]['weighted_score'].sum())\n",
    "    \n",
    "    # Determine signal direction\n",
    "    if buy_score > sell_score and net_score > params.min_net_score:\n",
    "        signal_direction = 'BUY'\n",
    "    elif sell_score > buy_score and abs(net_score) > params.min_net_score:\n",
    "        signal_direction = 'SELL'\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "    # Calculate signal strength\n",
    "    signal_strength = abs(net_score) / params.min_net_score\n",
    "    \n",
    "    return {\n",
    "        'symbol': window_data['SYMBOL'].iloc[0],\n",
    "        'company': window_data['COMPANY'].iloc[0],\n",
    "        'signal_date': signal_date,\n",
    "        'signal_direction': signal_direction,\n",
    "        'signal_strength': signal_strength,\n",
    "        'net_score': net_score,\n",
    "        'unique_insiders': unique_insiders,\n",
    "        'total_transactions': len(window_data),\n",
    "        'buy_score': buy_score,\n",
    "        'sell_score': sell_score\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31f2658c",
   "metadata": {},
   "source": [
    "## Signal Validation and Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e442e268",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_overlapping_signals(signals_df, params):\n",
    "    \"\"\"Remove overlapping signals for same company\"\"\"\n",
    "    filtered_signals = []\n",
    "    \n",
    "    for symbol in signals_df['symbol'].unique():\n",
    "        company_signals = signals_df[signals_df['symbol'] == symbol].copy()\n",
    "        company_signals = company_signals.sort_values('signal_date')\n",
    "        \n",
    "        last_signal_date = None\n",
    "        for _, signal in company_signals.iterrows():\n",
    "            if (last_signal_date is None or \n",
    "                (signal['signal_date'] - last_signal_date).days > params.signal_hold_period):\n",
    "                filtered_signals.append(signal)\n",
    "                last_signal_date = signal['signal_date']\n",
    "    \n",
    "    return pd.DataFrame(filtered_signals)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdb9d939",
   "metadata": {},
   "source": [
    "#### Quality Scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d23fe56f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_quality_score(signals_df):\n",
    "    \"\"\"Add quality score to signals\"\"\"\n",
    "    # Normalize signal strength\n",
    "    max_strength = signals_df['signal_strength'].max()\n",
    "    signals_df['normalized_strength'] = signals_df['signal_strength'] / max_strength\n",
    "    \n",
    "    # Calculate quality score based on multiple factors\n",
    "    signals_df['quality_score'] = (\n",
    "        0.4 * signals_df['normalized_strength'] +\n",
    "        0.3 * (signals_df['unique_insiders'] / signals_df['unique_insiders'].max()) +\n",
    "        0.3 * (signals_df['total_transactions'] / signals_df['total_transactions'].max())\n",
    "    )\n",
    "    \n",
    "    return signals_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bd2b3a1",
   "metadata": {},
   "source": [
    "## Portfolio Construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4636a757",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_position_sizes(signals_df, total_capital=1000000):\n",
    "    \"\"\"Calculate position sizes based on signal quality\"\"\"\n",
    "    # Filter for high quality signals\n",
    "    high_quality_signals = signals_df[signals_df['quality_score'] >= 0.6]\n",
    "    \n",
    "    # Calculate position sizes\n",
    "    total_quality_score = high_quality_signals['quality_score'].sum()\n",
    "    high_quality_signals['position_size'] = (\n",
    "        high_quality_signals['quality_score'] / total_quality_score * total_capital\n",
    "    )\n",
    "    \n",
    "    return high_quality_signals\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3a926479",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_diversification_rules(portfolio_df, max_position_pct=0.15):\n",
    "    \"\"\"Apply diversification constraints\"\"\"\n",
    "    total_capital = portfolio_df['position_size'].sum()\n",
    "    max_position_size = total_capital * max_position_pct\n",
    "    \n",
    "    # Cap individual positions\n",
    "    portfolio_df['position_size'] = portfolio_df['position_size'].clip(upper=max_position_size)\n",
    "    \n",
    "    # Rebalance to maintain total capital\n",
    "    scale_factor = total_capital / portfolio_df['position_size'].sum()\n",
    "    portfolio_df['position_size'] *= scale_factor\n",
    "    \n",
    "    return portfolio_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e421a10c",
   "metadata": {},
   "source": [
    "## Backtesting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b4090978",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_price_data(symbols):\n",
    "    \"\"\"Load historical price data for backtesting\"\"\"\n",
    "    # This would typically connect to a financial data provider\n",
    "    # For demonstration, we'll create a placeholder\n",
    "    price_data = {}\n",
    "    for symbol in symbols:\n",
    "        # Placeholder for actual price data loading\n",
    "        price_data[symbol] = generate_mock_price_data(symbol)\n",
    "    return price_data\n",
    "\n",
    "def generate_mock_price_data(symbol):\n",
    "    \"\"\"Generate mock price data for demonstration\"\"\"\n",
    "    dates = pd.date_range('2022-01-01', '2025-07-15', freq='D')\n",
    "    prices = 100 * np.cumprod(1 + np.random.normal(0, 0.02, len(dates)))\n",
    "    return pd.DataFrame({'date': dates, 'price': prices})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "abd11ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_backtest(portfolio_df, price_data, params):\n",
    "    \"\"\"Run backtesting on the consensus strategy\"\"\"\n",
    "    results = []\n",
    "    \n",
    "    for _, position in portfolio_df.iterrows():\n",
    "        symbol = position['symbol']\n",
    "        entry_date = position['signal_date']\n",
    "        exit_date = entry_date + timedelta(days=params.signal_hold_period)\n",
    "        \n",
    "        # Get price data for this symbol\n",
    "        symbol_prices = price_data.get(symbol)\n",
    "        if symbol_prices is None:\n",
    "            continue\n",
    "        \n",
    "        # Calculate returns\n",
    "        entry_price = get_price_on_date(symbol_prices, entry_date)\n",
    "        exit_price = get_price_on_date(symbol_prices, exit_date)\n",
    "        \n",
    "        if entry_price and exit_price:\n",
    "            if position['signal_direction'] == 'BUY':\n",
    "                return_pct = (exit_price - entry_price) / entry_price\n",
    "            else:  # SELL\n",
    "                return_pct = (entry_price - exit_price) / entry_price\n",
    "            \n",
    "            results.append({\n",
    "                'symbol': symbol,\n",
    "                'entry_date': entry_date,\n",
    "                'exit_date': exit_date,\n",
    "                'entry_price': entry_price,\n",
    "                'exit_price': exit_price,\n",
    "                'return_pct': return_pct,\n",
    "                'position_size': position['position_size'],\n",
    "                'pnl': return_pct * position['position_size']\n",
    "            })\n",
    "    \n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "def get_price_on_date(price_data, target_date):\n",
    "    \"\"\"Get price on a specific date\"\"\"\n",
    "    # ensure your date column is real datetime\n",
    "    price_data['date'] = pd.to_datetime(price_data['date'])\n",
    "    # set it as the index, sorted\n",
    "    price_data = price_data.set_index('date').sort_index()\n",
    "\n",
    "    # .asof will now look up the last index ≤ target_date\n",
    "    price = price_data['price'].asof(target_date)\n",
    "    return None if pd.isna(price) else price\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df523656",
   "metadata": {},
   "source": [
    "## Performance Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "cc1a099f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_performance_metrics(backtest_results):\n",
    "    \"\"\"Calculate comprehensive performance metrics\"\"\"\n",
    "    if len(backtest_results) == 0:\n",
    "        return {}\n",
    "    \n",
    "    returns = backtest_results['return_pct']\n",
    "    pnl = backtest_results['pnl']\n",
    "    \n",
    "    metrics = {\n",
    "        'total_trades': len(backtest_results),\n",
    "        'total_return': pnl.sum(),\n",
    "        'win_rate': (returns > 0).mean(),\n",
    "        'avg_return': returns.mean(),\n",
    "        'volatility': returns.std(),\n",
    "        'sharpe_ratio': returns.mean() / returns.std() if returns.std() > 0 else 0,\n",
    "        'max_drawdown': calculate_max_drawdown(pnl),\n",
    "        'profit_factor': calculate_profit_factor(pnl),\n",
    "        'avg_win': returns[returns > 0].mean() if (returns > 0).any() else 0,\n",
    "        'avg_loss': returns[returns < 0].mean() if (returns < 0).any() else 0\n",
    "    }\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "def calculate_max_drawdown(pnl_series):\n",
    "    \"\"\"Calculate maximum drawdown\"\"\"\n",
    "    cumulative_pnl = pnl_series.cumsum()\n",
    "    rolling_max = cumulative_pnl.expanding().max()\n",
    "    drawdown = cumulative_pnl - rolling_max\n",
    "    return drawdown.min()\n",
    "\n",
    "def calculate_profit_factor(pnl_series):\n",
    "    \"\"\"Calculate profit factor\"\"\"\n",
    "    gross_profit = pnl_series[pnl_series > 0].sum()\n",
    "    gross_loss = abs(pnl_series[pnl_series < 0].sum())\n",
    "    return gross_profit / gross_loss if gross_loss > 0 else np.inf\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf4786de",
   "metadata": {},
   "source": [
    "## Compile Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "6ca9abab",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConsensusInsiderStrategy:\n",
    "    def __init__(self, params=None):\n",
    "        self.params = params or ConsensusParameters()\n",
    "        self.raw_data = None\n",
    "        self.cleaned_data = None\n",
    "        self.signals = None\n",
    "        self.portfolio = None\n",
    "        self.backtest_results = None\n",
    "        self.performance_metrics = None\n",
    "    \n",
    "    def load_data(self, file_path):\n",
    "        \"\"\"Load and clean data\"\"\"\n",
    "        self.raw_data = load_and_clean_data(file_path)\n",
    "        self.cleaned_data = self.preprocess_data()\n",
    "        return self\n",
    "    \n",
    "    def preprocess_data(self):\n",
    "        \"\"\"Preprocess the data\"\"\"\n",
    "        df = filter_relevant_data(self.raw_data)\n",
    "        df = add_insider_weights(df)\n",
    "        df = calculate_transaction_metrics(df)\n",
    "        return df\n",
    "    \n",
    "    def generate_signals(self):\n",
    "        \"\"\"Generate consensus signals\"\"\"\n",
    "        self.signals = generate_consensus_signals(self.cleaned_data, self.params)\n",
    "        self.signals = filter_overlapping_signals(self.signals, self.params)\n",
    "        self.signals = add_quality_score(self.signals)\n",
    "        return self\n",
    "    \n",
    "    def build_portfolio(self, total_capital=1000000):\n",
    "        \"\"\"Build portfolio\"\"\"\n",
    "        self.portfolio = calculate_position_sizes(self.signals, total_capital)\n",
    "        self.portfolio = apply_diversification_rules(self.portfolio)\n",
    "        return self\n",
    "    \n",
    "    def run_backtest(self, price_data=None):\n",
    "        \"\"\"Run backtesting\"\"\"\n",
    "        if price_data is None:\n",
    "            symbols = self.portfolio['symbol'].unique()\n",
    "            price_data = load_price_data(symbols)\n",
    "        \n",
    "        self.backtest_results = run_backtest(self.portfolio, price_data, self.params)\n",
    "        self.performance_metrics = calculate_performance_metrics(self.backtest_results)\n",
    "        return self\n",
    "    \n",
    "    def get_results(self):\n",
    "        \"\"\"Get comprehensive results\"\"\"\n",
    "        return {\n",
    "            'signals': self.signals,\n",
    "            'portfolio': self.portfolio,\n",
    "            'backtest_results': self.backtest_results,\n",
    "            'performance_metrics': self.performance_metrics\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "7ee16e15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_parameter_sweep(param_sets, file_path='CF-Insider-Trading-equities-14-07-2022-to-14-07-2025.csv', \n",
    "                        total_capital=1000000):\n",
    "    \"\"\"\n",
    "    Run the full strategy for multiple parameter sets and collect performance metrics.\n",
    "    \n",
    "    :param param_sets: List of dictionaries, each with keys like 'lookback_window', 'min_insiders', etc.\n",
    "    :param file_path: Path to the data file.\n",
    "    :param total_capital: Starting capital for portfolio building.\n",
    "    :return: Dictionary where keys are parameter set indices, values are performance metrics dicts.\n",
    "    \"\"\"\n",
    "    sweep_results = {}\n",
    "    \n",
    "    for i, params_dict in enumerate(param_sets):\n",
    "        # Create parameters object with custom values\n",
    "        params = ConsensusParameters(**params_dict)\n",
    "        \n",
    "        # Initialize and run strategy\n",
    "        strategy = ConsensusInsiderStrategy(params=params)\n",
    "        strategy.load_data(file_path)\n",
    "        strategy.generate_signals()\n",
    "        strategy.build_portfolio(total_capital=total_capital)\n",
    "        strategy.run_backtest()\n",
    "        \n",
    "        # Get and store results\n",
    "        results = strategy.get_results()\n",
    "        sweep_results[f'Set_{i+1}'] = {\n",
    "            'parameters': params_dict,\n",
    "            'performance_metrics': results['performance_metrics']\n",
    "        }\n",
    "        \n",
    "        # Print summary for this set\n",
    "        print(f\"\\nResults for Parameter Set {i+1}: {params_dict}\")\n",
    "        for metric, value in results['performance_metrics'].items():\n",
    "            print(f\"{metric}: {value:.4f}\")\n",
    "    \n",
    "    return sweep_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "eb1f08b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance Metrics:\n",
      "total_trades: 9.0000\n",
      "total_return: 9811.4293\n",
      "win_rate: 0.7778\n",
      "avg_return: 0.0100\n",
      "volatility: 0.0151\n",
      "sharpe_ratio: 0.6649\n",
      "max_drawdown: -2849.5178\n",
      "profit_factor: 4.4432\n",
      "avg_win: 0.0162\n",
      "avg_loss: -0.0117\n"
     ]
    }
   ],
   "source": [
    "# Initialize strategy\n",
    "strategy = ConsensusInsiderStrategy()\n",
    "\n",
    "# Load and process data\n",
    "strategy.load_data('CF-Insider-Trading-equities-14-07-2022-to-14-07-2025.csv')\n",
    "\n",
    "# Generate signals\n",
    "strategy.generate_signals()\n",
    "\n",
    "# Build portfolio\n",
    "strategy.build_portfolio(total_capital=1000000)\n",
    "\n",
    "# Run backtest\n",
    "strategy.run_backtest()\n",
    "\n",
    "# Get results\n",
    "results = strategy.get_results()\n",
    "\n",
    "# Display performance metrics\n",
    "print(\"Performance Metrics:\")\n",
    "for metric, value in results['performance_metrics'].items():\n",
    "    print(f\"{metric}: {value:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "insider_trading",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
